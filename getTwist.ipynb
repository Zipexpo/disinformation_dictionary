{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\ngu00336\\AppData\\Roaming\\Python\\Python37\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ngu00336\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ngu00336\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ngu00336\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import tweepy\n",
    "from parse_raw_tweet import parse_raw_tweet\n",
    "import base64\n",
    "import yaml\n",
    "import time\n",
    "from getTopic import handleData\n",
    "from getTopic import df2tweet\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from Helper import Helper\n",
    "from Tweet import Tweet\n",
    "import re\n",
    "\n",
    "# CONSUMER_KEY = st.secrets['CONSUMER_KEY']\n",
    "# CONSUMER_SECRET = st.secrets['CONSUMER_SECRET']\n",
    "# ACCESS_TOKEN = st.secrets['ACCESS_TOKEN']\n",
    "# ACCESS_SECRET = st.secrets['ACCESS_SECRET']\n",
    "\n",
    "CONSUMER_KEY = 'NklB4SGVsSjpXLYWVn6lXxd7U'\n",
    "CONSUMER_SECRET = 'rUMAU5dIpIRTImwIBNfgxxYWwP7Y2pkgjB3X36J7JkjkfLIkMu'\n",
    "ACCESS_TOKEN = '1440879620971184129-HyGEUpcpEdHedXusFfaxRZ0NlyD1hA' #Authorization: Bearer\n",
    "ACCESS_SECRET = 'OIwnv2pjyT9qjgFU1PnpUIbSSWittZFnoGMojUDNAz58B'\n",
    "# Bearer: AAAAAAAAAAAAAAAAAAAAADU8UAEAAAAAGVXvwcwh%2BgCv%2FFhm7rDZgdmUv4k%3DeCwAbKOPDfhNcYENvdv4B8B9nGTR2Xje6whEqCOPEI8bpks4vn\n",
    "def read_config():\n",
    "\n",
    "\t## authenticate\n",
    "\tauth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\tauth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\tapi = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)\n",
    "\n",
    "\n",
    "\treturn api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "topics_cols=[]\n",
    "with open(\"data/keywords.json\", \"r\") as read_file:\n",
    "    topics_cols =  list(json.load(read_file))\n",
    "\n",
    "def addValue(df2,i,keyIndex,result):\n",
    "    c = result[i][0]['top'+str(keyIndex)].values[0]\n",
    "    df2.at[i,c] = result[i][0]['score'+str(keyIndex)].values[0]\n",
    "    df2.at[i,c+\"_keywords\"] = str(result[i][1][c+'_keywords'].values[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def savetweet(df2,result,fileName):\n",
    "    for c in topics_cols:\n",
    "        df2[c]=0\n",
    "        df2[c+\"_keywords\"]='()'\n",
    "    for i in tqdm(range(0,df2.shape[0])):\n",
    "        addValue(df2,i,1,result)\n",
    "        addValue(df2,i,2,result)\n",
    "        addValue(df2,i,3,result)\n",
    "        addValue(df2,i,4,result)\n",
    "        addValue(df2,i,5,result)\n",
    "    df2.to_csv('data/real_10_14_22_2021/'+fileName+'_topic.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "api = read_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "startDate = datetime(2021, 10, 14, 0, 0, 0)\n",
    "endDate =   datetime(2021, 10, 21, 0, 0, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def getFromsource(username):\n",
    "    tweets = []\n",
    "    tmpTweets = api.user_timeline(username)\n",
    "    \n",
    "    \n",
    "    for tweet in tmpTweets:\n",
    "        if tweet.created_at < endDate and tweet.created_at > startDate:\n",
    "            tweets.append(tweet)\n",
    "    result = []\n",
    "    df2 = pd.DataFrame(columns=['tweetid','userid','user_display_name','tweet_time'])\n",
    "    while (tmpTweets[-1].created_at > startDate):\n",
    "        tmpTweets = api.user_timeline(username, max_id = tmpTweets[-1].id)\n",
    "        for tweet in tmpTweets:\n",
    "            if tweet.created_at < endDate and tweet.created_at > startDate:\n",
    "                raw_tweet = api.get_status(tweet.id, tweet_mode=\"extended\")._json\n",
    "                [top_n_topics_df,keywords_appearing_df] = handleData(raw_tweet)\n",
    "                result.append([top_n_topics_df,keywords_appearing_df])\n",
    "                df = {'tweetid':raw_tweet['id'],'userid':raw_tweet['user']['id'],'user_display_name':raw_tweet['user']['name'],\n",
    "                      'tweet_time':raw_tweet['created_at']}\n",
    "                df2 = df2.append(df, ignore_index = True)\n",
    "    savetweet(df2,result,username)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "listNews = pd.read_excel(\"data/News List and dictionary.xlsx\",sheet_name='News list')\n",
    "listNews = listNews[pd.isna(listNews[\"Type\"])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=887.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c08a509c71744afcbf8f7ad17bf86471"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "104 sacbee_news\n",
      "expandURL(link) https://trib.al/HfH3Umv\n",
      "faile\n",
      "105 ocregister\n",
      "faile\n",
      "106 EastBayTimes\n",
      "faile\n",
      "107 sfchronicle\n",
      "faile\n",
      "108 FresnoBee\n",
      "faile\n",
      "109 sdut\n",
      "faile\n",
      "110 pressenterprise\n",
      "faile\n",
      "111 sfexaminer\n",
      "faile\n",
      "112 SGVTribune\n",
      "faile\n",
      "113 DailyBreezeNews\n",
      "faile\n",
      "114 modbee\n",
      "faile\n",
      "115 ladailynews\n",
      "faile\n",
      "116 NorthBayNews\n",
      "faile\n",
      "117 presstelegram\n",
      "faile\n",
      "118 ivdailybulletin\n",
      "faile\n",
      "119 SLOTribune\n",
      "faile\n",
      "120 MyDesert\n",
      "faile\n",
      "121 BreakingNews_RS\n",
      "faile\n",
      "122 ChicoER\n",
      "faile\n",
      "123 smdailypress\n",
      "faile\n",
      "124 sbnpnews\n",
      "faile\n",
      "125 MontereyHerald\n",
      "faile\n",
      "126 eurekaTS\n",
      "faile\n",
      "127 Bakersfieldcali\n",
      "faile\n",
      "128 MercedSunStar\n",
      "faile\n",
      "129 TheMendoVoice\n",
      "faile\n",
      "130 appealdemocrat\n",
      "faile\n",
      "131 NapaRegister\n",
      "faile\n",
      "132 redbluffnews\n",
      "faile\n",
      "133 RedlandsNews\n",
      "faile\n",
      "134 salnews\n",
      "faile\n",
      "135 PasStarNews\n",
      "faile\n",
      "136 recorderonline\n",
      "faile\n",
      "137 smdailyjournal\n",
      "faile\n",
      "138 SCVSignal\n",
      "faile\n",
      "139 scsentinel\n",
      "faile\n",
      "140 vcstar\n",
      "faile\n",
      "141 woodlandnews\n",
      "faile\n",
      "142 WhittierNews\n",
      "faile\n",
      "143 EastBayExpress\n",
      "faile\n",
      "144 thepress_net\n",
      "faile\n",
      "145 Alameda_Sun\n",
      "faile\n",
      "146 TimesAdvocate\n",
      "faile\n",
      "147 hmbreview\n",
      "faile\n",
      "148 turlockjournal\n",
      "faile\n",
      "149 valleycenter\n",
      "faile\n",
      "150 OVN\n",
      "faile\n",
      "151 TheMountainMess\n",
      "faile\n",
      "152 MadTrib\n",
      "faile\n",
      "153 LarchmontChron\n",
      "faile\n",
      "154 MendocinoBeacon\n",
      "faile\n",
      "155 mcweekly\n",
      "faile\n",
      "156 PalisadianPost\n",
      "faile\n",
      "157 thescweekly\n",
      "faile\n",
      "158 cvweekly\n",
      "faile\n",
      "159 mattosnews\n",
      "faile\n",
      "160 SCMbulletin\n",
      "faile\n",
      "161 nccurrent\n",
      "faile\n",
      "162 coastnewsgroup\n",
      "faile\n",
      "163 LaOpinionLA\n",
      "faile\n",
      "164 SbAmericannews\n",
      "faile\n",
      "165 FBAdvocateNews\n",
      "faile\n",
      "166 TheWillitsNews\n",
      "faile\n",
      "167 sbsun\n",
      "faile\n",
      "168 LA_WaveNews\n",
      "faile\n",
      "169 OaklandPostNews\n",
      "faile\n",
      "170 SFGate\n",
      "faile\n",
      "171 DVCInquirer\n",
      "faile\n",
      "172 GCC_ElVaq\n",
      "faile\n",
      "173 peraltacitizen\n",
      "faile\n",
      "174 ValleyStarNews\n",
      "faile\n",
      "175 LMC_Experience\n",
      "faile\n",
      "176 LALoyolan\n",
      "faile\n",
      "177 thecampanil\n",
      "faile\n",
      "178 ePasadenaNow\n",
      "faile\n",
      "179 TheDailyAztec\n",
      "faile\n",
      "180 GGXnews\n",
      "faile\n",
      "181 SpartanDaily\n",
      "faile\n",
      "182 TheSantaClara\n",
      "faile\n",
      "183 StanfordReview\n",
      "faile\n",
      "184 NewUniversity\n",
      "faile\n",
      "185 dailynexus\n",
      "faile\n",
      "186 cityonahill\n",
      "faile\n",
      "187 GoodTimesSC\n",
      "faile\n",
      "188 SFFoghorn\n",
      "faile\n",
      "189 dailytrojan\n",
      "faile\n",
      "190 quakercampus\n",
      "faile\n",
      "191 OrovilleMR\n",
      "faile\n",
      "192 OakTribNews\n",
      "faile\n",
      "193 ParadisePost\n",
      "faile\n",
      "194 berkeleyside\n",
      "faile\n",
      "195 Oaklandside\n",
      "faile\n",
      "196 BeverlyPress\n",
      "faile\n",
      "197 LarchmontBuzz\n",
      "faile\n",
      "198 TheMalibuTimes\n",
      "faile\n",
      "199 BrentwoodPatch\n",
      "faile\n",
      "200 denverpost\n",
      "faile\n",
      "201 csgazette\n",
      "faile\n",
      "202 dailycamera\n",
      "faile\n",
      "203 ChieftainNews\n",
      "faile\n",
      "204 DailySentinelGJ\n",
      "faile\n",
      "205 TimesCall\n",
      "faile\n",
      "206 Coloradoan\n",
      "faile\n",
      "207 reporterherald\n",
      "faile\n",
      "208 DurangoHerald\n",
      "faile\n",
      "209 ccdr\n",
      "faile\n",
      "210 AspenDailyNews\n",
      "faile\n",
      "211 TheAspenTimes\n",
      "faile\n",
      "212 SentinelColo\n",
      "faile\n",
      "213 BerthoudSurvey\n",
      "faile\n",
      "214 boulderweekly\n",
      "faile\n",
      "215 Metrowestnews\n",
      "faile\n",
      "216 bfld_enterprise\n",
      "faile\n",
      "217 coloradodaily\n",
      "faile\n",
      "218 CoHoWeekly\n",
      "faile\n",
      "219 csindependent\n",
      "faile\n",
      "220 DoveCreekPress\n",
      "faile\n",
      "221 VailDaily\n",
      "faile\n",
      "222 news_hometown\n",
      "faile\n",
      "223 The_JT_Breeze\n",
      "faile\n",
      "224 JournalAdvocate\n",
      "faile\n",
      "225 KiowaPress\n",
      "faile\n",
      "226 steamboatpilot\n",
      "faile\n",
      "227 SummitDailyNews\n",
      "faile\n",
      "228 TelluridePlanet\n",
      "faile\n",
      "229 bizwestmedia\n",
      "faile\n",
      "230 CSBizJournal\n",
      "faile\n",
      "231 denbizjournal\n",
      "faile\n",
      "232 LaPrensadeCO\n",
      "faile\n",
      "233 LaVozColorado\n",
      "faile\n",
      "234 DUS_Tweets\n",
      "faile\n",
      "235 DenverVOICE\n",
      "faile\n",
      "236 CSUCollegian\n",
      "faile\n",
      "237 The_CUI\n",
      "faile\n",
      "238 frontpagefrcc\n",
      "faile\n",
      "239 CMU_Criterion\n",
      "faile\n",
      "240 UNCMirror\n",
      "faile\n",
      "241 CTNewsJunkie\n",
      "faile\n",
      "242 StamAdvocate\n",
      "faile\n",
      "243 TheBristolPress\n",
      "faile\n",
      "244 thechroniclect\n",
      "faile\n",
      "245 CTMirror\n",
      "faile\n",
      "246 connpost\n",
      "faile\n",
      "247 thedayct\n",
      "faile\n",
      "248 GreenwichTime\n",
      "faile\n",
      "249 hartfordcourant\n",
      "faile\n",
      "250 NewBritHerald\n",
      "faile\n",
      "251 TheHourNews\n",
      "faile\n",
      "252 JournalInquirer\n",
      "faile\n",
      "253 Middletownpress\n",
      "faile\n",
      "254 nhregister\n",
      "faile\n",
      "255 NewsTimes\n",
      "faile\n",
      "256 Record_Journal\n",
      "faile\n",
      "257 rep_am\n",
      "faile\n",
      "258 DarienTimes\n",
      "faile\n",
      "259 fairfieldpatch\n",
      "faile\n",
      "260 TheNewtownBee\n",
      "faile\n",
      "261 RidgefieldPress\n",
      "faile\n",
      "262 CTJewishLedger\n",
      "faile\n",
      "263 elsolnews\n",
      "faile\n",
      "264 lavozhispanact\n",
      "faile\n",
      "265 ChargerBulletin\n",
      "faile\n",
      "266 the_dailycampus\n",
      "faile\n",
      "267 FairfieldMirror\n",
      "faile\n",
      "268 wesleyanargus\n",
      "faile\n",
      "269 yaledailynews\n",
      "faile\n",
      "270 CapeGazette\n",
      "faile\n",
      "271 TheStateNews\n",
      "faile\n",
      "272 delawareonline\n",
      "faile\n",
      "273 nwkpost\n",
      "faile\n",
      "274 HOYenDE\n",
      "faile\n",
      "275 udreview\n",
      "faile\n",
      "276 TranscriptMOT\n",
      "faile\n",
      "277 bradentonherald\n",
      "faile\n",
      "278 BradentonTimes\n",
      "faile\n",
      "279 dbnewsjournal\n",
      "faile\n",
      "280 FLDailyPost\n",
      "faile\n",
      "281 jaxdotcom\n",
      "faile\n",
      "282 Florida_Today\n",
      "faile\n",
      "283 folioweekly\n",
      "faile"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in tqdm(range(0,listNews.shape[0])):\n",
    "    try:\n",
    "        news = listNews.iloc[i]\n",
    "        user_name = news['Twitter Link'].split('/')[-1]\n",
    "        print(i,user_name)\n",
    "        getFromsource(user_name)\n",
    "    except:\n",
    "        print('faile')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}